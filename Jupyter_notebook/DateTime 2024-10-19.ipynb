{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "042d238a-fb7f-4260-829f-20570d039ddd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=5376419441612485#setting/sparkui/1019-140830-yx0lm2zz/driver-5934699455763931491\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=5376419441612485#setting/sparkui/1019-140830-yx0lm2zz/driver-5934699455763931491\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26192fd2-d309-44c7-9a29-fd771aa2cda4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp,current_date,date_add,date_sub,datediff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1952e2c-78c5-470c-9a6f-0f162d46a8b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format,dayofmonth,dayofweek,dayofyear,month,days,year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77e1a4a7-9f5b-4cf0-8a29-cdee52827323",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'current_date()'>"
     ]
    }
   ],
   "source": [
    "display(current_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f29452a0-1e94-44ab-967d-adf77f9edd83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "633072c7-8663-4e75-879a-d8ca0797fe3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import months_between,add_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83d0fbaf-a47d-46db-b36d-5eb7174760ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_spark=spark.read.csv('dbfs:/FileStore/employee.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45dfbe1e-97a5-449a-a399-365102d8407b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|\n+-----+--------+------------------+---------------+-----------+------+\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|\n+-----+--------+------------------+---------------+-----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4427d26e-2bf8-4d1c-b70b-2b4aec66a410",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+----------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|  New date|\n+-----+--------+------------------+---------------+-----------+------+----------+\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|2024-10-19|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|2024-10-19|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|2024-10-19|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|2024-10-19|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000|2024-10-19|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|2024-10-19|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|2024-10-19|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|2024-10-19|\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|2024-10-19|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|2024-10-19|\n+-----+--------+------------------+---------------+-----------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumn('New date',current_date()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c739d2e-a4f1-411a-8be4-74b3c2c2f874",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_timestamp=df_spark.withColumn('New_time',current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21825583-03a8-4778-8ac2-83982e47828b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+-----------------------+\n|Empid|Name    |Skills            |Date of Joining|Dept       |Salary|New_time               |\n+-----+--------+------------------+---------------+-----------+------+-----------------------+\n|1    |Abhishek|python,sql,excel  |2020-01-01     |DataScience|100000|2024-10-19 14:32:00.355|\n|2    |Nitesh  |sap,word,excel    |2017-06-10     |Finance    |150000|2024-10-19 14:32:00.355|\n|3    |Aniket  |Java,sql          |2021-02-20     |Development|200000|2024-10-19 14:32:00.355|\n|4    |Sandeep |Aws,postgre,python|2020-01-01     |Development|125000|2024-10-19 14:32:00.355|\n|5    |Rahul   |Azure,scala       |2018-05-05     |DataScience|175000|2024-10-19 14:32:00.355|\n|6    |Venkat  |Slang,java        |2019-05-10     |Finance    |250000|2024-10-19 14:32:00.355|\n|7    |Arunesh |finacle,isense    |2021-02-20     |Finance    |150000|2024-10-19 14:32:00.355|\n|8    |Sangeeta|Dermatoloist      |2022-10-30     |DataScience|100000|2024-10-19 14:32:00.355|\n|9    |Yuvraj  |ABCD              |2023-06-01     |Development|200000|2024-10-19 14:32:00.355|\n|10   |Tushar  |running           |2021-10-20     |Finance    |150000|2024-10-19 14:32:00.355|\n+-----+--------+------------------+---------------+-----------+------+-----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_timestamp.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53bea920-1ca5-43ad-acfd-f328fefe5c70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+------------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|day_of_month|\n+-----+--------+------------------+---------------+-----------+------+------------+\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|           1|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|          10|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|          20|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|           1|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000|           5|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|          10|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|          20|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|          30|\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|           1|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|          20|\n+-----+--------+------------------+---------------+-----------+------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('*',dayofmonth('Date of Joining').alias('day_of_month')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e3d556e-a7c4-45ee-a9a6-8b986f8c1402",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+-----------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|day_of_week|\n+-----+--------+------------------+---------------+-----------+------+-----------+\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|          4|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|          7|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|          7|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|          4|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000|          7|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|          6|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|          7|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|          1|\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|          5|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|          4|\n+-----+--------+------------------+---------------+-----------+------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('*',dayofweek('Date of Joining').alias('day_of_week')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90a17daa-7be7-4862-bf16-05eb66f73b74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----------------+---------------+-----------+------+--------------------+\n|Empid|    Name|          Skills|Date of Joining|       Dept|Salary|            New_time|\n+-----+--------+----------------+---------------+-----------+------+--------------------+\n|    1|Abhishek|python,sql,excel|     2020-01-01|DataScience|100000|2024-10-19 14:37:...|\n|    2|  Nitesh|  sap,word,excel|     2017-06-10|    Finance|150000|2024-10-19 14:37:...|\n+-----+--------+----------------+---------------+-----------+------+--------------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_timestamp.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caaad8fc-e47a-4cfa-a26b-87c84542a504",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n|            New_time|dayofweek(New_time)|\n+--------------------+-------------------+\n|2024-10-19 14:38:...|                  7|\n|2024-10-19 14:38:...|                  7|\n+--------------------+-------------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_timestamp.select('New_time',dayofweek('New_time')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07f27b85-8ff3-4166-952e-4ac318dfba62",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n|            New_time|dayofyear(New_time)|\n+--------------------+-------------------+\n|2024-10-19 14:38:...|                293|\n|2024-10-19 14:38:...|                293|\n+--------------------+-------------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_timestamp.select('New_time',dayofyear('New_time')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd43b71c-4348-4ab0-a81d-4d2d768f8a67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n|            New_time|month(New_time)|\n+--------------------+---------------+\n|2024-10-19 14:39:...|             10|\n|2024-10-19 14:39:...|             10|\n+--------------------+---------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_timestamp.select('New_time',month('New_time')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3707f4b8-1b92-43fa-ba46-2f4321bd0bc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n|            New_time|year(New_time)|\n+--------------------+--------------+\n|2024-10-19 14:39:...|          2024|\n|2024-10-19 14:39:...|          2024|\n+--------------------+--------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_timestamp.select('New_time',year('New_time')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ecb247d-3319-45f5-9143-8d60d6555b63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+----------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|  New_date|\n+-----+--------+------------------+---------------+-----------+------+----------+\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|2020-01-06|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|2017-06-15|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|2021-02-25|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|2020-01-06|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000|2018-05-10|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|2019-05-15|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|2021-02-25|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|2022-11-04|\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|2023-06-06|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|2021-10-25|\n+-----+--------+------------------+---------------+-----------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumn('New_date',date_add('Date of Joining',5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbaebb3d-e9fa-4a26-ad8e-9effeefadf17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+----------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|  New_date|\n+-----+--------+------------------+---------------+-----------+------+----------+\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|2019-12-27|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|2017-06-05|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|2021-02-15|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|2019-12-27|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000|2018-04-30|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|2019-05-05|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|2021-02-15|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|2022-10-25|\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|2023-05-27|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|2021-10-15|\n+-----+--------+------------------+---------------+-----------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumn('New_date',date_sub('Date of Joining',5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "326c6d00-0505-4a8a-970e-e32d678386bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+----------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|  New_date|\n+-----+--------+------------------+---------------+-----------+------+----------+\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|2019-12-27|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|2017-06-05|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|2021-02-15|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|2019-12-27|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000|2018-04-30|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|2019-05-05|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|2021-02-15|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|2022-10-25|\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|2023-05-27|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|2021-10-15|\n+-----+--------+------------------+---------------+-----------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumn('New_date',date_add('Date of Joining',-5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "447abb3c-8558-4c04-abdb-10eb8653235c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+--------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|New_date|\n+-----+--------+------------------+---------------+-----------+------+--------+\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|     506|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|     720|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|    1095|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|    1337|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|    1337|\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|    1753|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|    1753|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|    1989|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000|    2359|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|    2688|\n+-----+--------+------------------+---------------+-----------+------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumn('New_date',datediff(current_date(),'Date of Joining')).sort('New_date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c64ee1b3-e85c-483f-b456-b37af7f48499",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+-----------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|   New_date|\n+-----+--------+------------------+---------------+-----------+------+-----------+\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|57.58064516|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|88.29032258|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|43.96774194|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|57.58064516|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000| 77.4516129|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|65.29032258|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|43.96774194|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|23.64516129|\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|16.58064516|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|35.96774194|\n+-----+--------+------------------+---------------+-----------+------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumn('New_date',months_between(current_date(),'Date of Joining')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9213bf3c-c0eb-42c2-9da6-79ea39e30686",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+--------------------+-------------------------------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|            New_time|date_format(New_time, dd/MM/yy)|\n+-----+--------+------------------+---------------+-----------+------+--------------------+-------------------------------+\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|2024-10-19 14:47:...|                       19/10/24|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|2024-10-19 14:47:...|                       19/10/24|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|2024-10-19 14:47:...|                       19/10/24|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|2024-10-19 14:47:...|                       19/10/24|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000|2024-10-19 14:47:...|                       19/10/24|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|2024-10-19 14:47:...|                       19/10/24|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|2024-10-19 14:47:...|                       19/10/24|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|2024-10-19 14:47:...|                       19/10/24|\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|2024-10-19 14:47:...|                       19/10/24|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|2024-10-19 14:47:...|                       19/10/24|\n+-----+--------+------------------+---------------+-----------+------+--------------------+-------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_timestamp.select('*',date_format('New_time','dd/MM/yy')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3007d4c-bcc7-4c87-b367-f1b49835d5df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+--------------------+---------------------------------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|            New_time|date_format(New_time, dd-MM-yyyy)|\n+-----+--------+------------------+---------------+-----------+------+--------------------+---------------------------------+\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|2024-10-19 14:48:...|                       19-10-2024|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|2024-10-19 14:48:...|                       19-10-2024|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|2024-10-19 14:48:...|                       19-10-2024|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|2024-10-19 14:48:...|                       19-10-2024|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000|2024-10-19 14:48:...|                       19-10-2024|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|2024-10-19 14:48:...|                       19-10-2024|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|2024-10-19 14:48:...|                       19-10-2024|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|2024-10-19 14:48:...|                       19-10-2024|\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|2024-10-19 14:48:...|                       19-10-2024|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|2024-10-19 14:48:...|                       19-10-2024|\n+-----+--------+------------------+---------------+-----------+------+--------------------+---------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_timestamp.select('*',date_format('New_time','dd-MM-yyyy')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a211c66f-114a-45f3-99be-cfed9267a978",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max,min,avg,count,sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a747ae0b-7615-444a-8967-ab1116541ed9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+--------+\n|       Dept|  max_date|   mindate|days_gap|\n+-----------+----------+----------+--------+\n|    Finance|2021-10-20|2017-06-10|    1593|\n|Development|2023-06-01|2020-01-01|    1247|\n|DataScience|2022-10-30|2018-05-05|    1639|\n+-----------+----------+----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df_spark.groupBy('Dept').agg(max('Date of Joining').alias('max_date'),min('Date of Joining').alias('mindate'),datediff(max('Date of Joining'),min('Date of Joining')).alias('days_gap')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17b6d3ae-370e-4f53-926f-15c4d175aa6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+--------------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|new_month_date|\n+-----+--------+------------------+---------------+-----------+------+--------------+\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|    2020-03-01|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|    2017-08-10|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|    2021-04-20|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|    2020-03-01|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000|    2018-07-05|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|    2019-07-10|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|    2021-04-20|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|    2022-12-30|\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|    2023-08-01|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|    2021-12-20|\n+-----+--------+------------------+---------------+-----------+------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumn('new_month_date',add_months('Date of Joining',2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66efef53-2709-4ac1-89f3-bec10c8c82ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date,next_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b877802e-616a-43b2-ae19-d24cfde4f4a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function to_date in module pyspark.sql.functions:\n\nto_date(col: 'ColumnOrName', format: Optional[str] = None) -> pyspark.sql.column.Column\n    Converts a :class:`~pyspark.sql.Column` into :class:`pyspark.sql.types.DateType`\n    using the optionally specified format. Specify formats according to `datetime pattern`_.\n    By default, it follows casting rules to :class:`pyspark.sql.types.DateType` if the format\n    is omitted. Equivalent to ``col.cast(\"date\")``.\n    \n    .. _datetime pattern: https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\n    \n    .. versionadded:: 2.2.0\n    \n    .. versionchanged:: 3.4.0\n        Support Spark Connect.\n    \n    Parameters\n    ----------\n    col : :class:`~pyspark.sql.Column` or str\n        input column of values to convert.\n    format: str, optional\n        format to use to convert date values.\n    \n    Returns\n    -------\n    :class:`~pyspark.sql.Column`\n        date value as :class:`pyspark.sql.types.DateType` type.\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame([('1997-02-28 10:30:00',)], ['t'])\n    >>> df.select(to_date(df.t).alias('date')).collect()\n    [Row(date=datetime.date(1997, 2, 28))]\n    \n    >>> df = spark.createDataFrame([('1997-02-28 10:30:00',)], ['t'])\n    >>> df.select(to_date(df.t, 'yyyy-MM-dd HH:mm:ss').alias('date')).collect()\n    [Row(date=datetime.date(1997, 2, 28))]\n\n"
     ]
    }
   ],
   "source": [
    "help(to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eff71294-a24d-46fa-841a-2df5be62d274",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+----------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|New-sunday|\n+-----+--------+------------------+---------------+-----------+------+----------+\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|2020-01-06|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|2017-06-12|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|2021-02-22|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|2020-01-06|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000|2018-05-07|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|2019-05-13|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|2021-02-22|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|2022-10-31|\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|2023-06-05|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|2021-10-25|\n+-----+--------+------------------+---------------+-----------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumn('New-sunday',next_day('Date of Joining','Monday')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d88cd2e-0d2b-4d47-96cc-d0414bd998a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------------------+---------------+-----------+------+----------+\n|Empid|    Name|            Skills|Date of Joining|       Dept|Salary|New-sunday|\n+-----+--------+------------------+---------------+-----------+------+----------+\n|    1|Abhishek|  python,sql,excel|     2020-01-01|DataScience|100000|2020-01-01|\n|    2|  Nitesh|    sap,word,excel|     2017-06-10|    Finance|150000|2017-06-10|\n|    3|  Aniket|          Java,sql|     2021-02-20|Development|200000|2021-02-20|\n|    4| Sandeep|Aws,postgre,python|     2020-01-01|Development|125000|2020-01-01|\n|    5|   Rahul|       Azure,scala|     2018-05-05|DataScience|175000|2018-05-05|\n|    6|  Venkat|        Slang,java|     2019-05-10|    Finance|250000|2019-05-10|\n|    7| Arunesh|    finacle,isense|     2021-02-20|    Finance|150000|2021-02-20|\n|    8|Sangeeta|      Dermatoloist|     2022-10-30|DataScience|100000|2022-10-30|\n|    9|  Yuvraj|              ABCD|     2023-06-01|Development|200000|2023-06-01|\n|   10|  Tushar|           running|     2021-10-20|    Finance|150000|2021-10-20|\n+-----+--------+------------------+---------------+-----------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumn('New-sunday',to_date('Date of Joining','dd-MM-YYYY')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cf7caa0-6b6d-4f10-87be-8c9ee48805c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DateTime 2024-10-19",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
